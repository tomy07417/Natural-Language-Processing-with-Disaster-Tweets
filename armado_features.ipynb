{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b404485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/tomy07417/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tomy07417/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ba27d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "with open(\"./words_desastres.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    words_desastres = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c7115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "train_df[['neg','neu','pos','compound']] = pd.DataFrame(\n",
    "    train_df.text.map(lambda x: sia.polarity_scores(x)).tolist(),\n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "train_df = train_df.join(\n",
    "    train_df['text'].apply(lambda x: pd.Series(sentiment_analyzer(x)[0]))\n",
    ").rename(columns={'label': 'sentimiento', 'score': 'score_global'})\n",
    "\n",
    "train_df['len'] = train_df.text.map(len)\n",
    "\n",
    "tokenizer = TweetTokenizer(\n",
    "    preserve_case=False,  \n",
    "    strip_handles=True,   \n",
    "    reduce_len=True       \n",
    ")\n",
    "\n",
    "def tokens(texto):\n",
    "    # 1Ô∏è‚É£ Reemplazar URLs\n",
    "    texto = re.sub(r\"http\\S+|www\\S+\", \" url \", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "\n",
    "    # 2Ô∏è‚É£ Tokenizar\n",
    "    toks = tokenizer.tokenize(texto)\n",
    "\n",
    "    # 3Ô∏è‚É£ Filtrar tokens (por ejemplo, eliminar signos o tokens cortos)\n",
    "    toks = [t for t in toks if len(t) > 2 and re.match(r\"^[a-z#]+$\", t)]\n",
    "\n",
    "    return toks\n",
    "\n",
    "def count_claves(texto):\n",
    "    text_tokens = tokens(texto)\n",
    "    count = sum(1 for word in words_desastres[:50] if word in text_tokens)\n",
    "    return count\n",
    "\n",
    "def count_hashtags(texto):\n",
    "    text_tokens = [t for t in tokenizer.tokenize(texto) if t.startswith('#')]\n",
    "    return len(text_tokens)\n",
    "\n",
    "train_df[['tiene_url', 'palabras_claves', 'hashtags']] = train_df.text.apply(lambda x: pd.Series([\"SI\", count_claves(x), count_hashtags(x)] if \"url\" in tokens(x) else [\"NO\", count_claves(x), count_hashtags(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff07fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomy07417/data-science/ml/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def limpiar_texto(texto):\n",
    "    # Reemplazar URLs por token\n",
    "    texto = re.sub(r\"http\\S+|www\\S+\", \" URL \", texto)\n",
    "    # Reemplazar menciones (@usuario)\n",
    "    texto = re.sub(r\"@\\w+\", \" USER \", texto)   \n",
    "    # Reemplazar hashtags (dejando la palabra)\n",
    "    texto = re.sub(r\"#(\\w+)\", r\" HASHTAG_\\1 \", texto) \n",
    "    # Reemplazar emojis (usando su significado textual)\n",
    "    texto = emoji.demojize(texto, language=\"en\")  # üòä ‚Üí :cara_sonriente:\n",
    "    texto = re.sub(r\":([a-zA-Z0-9_]+):\", r\" EMOJI_\\1 \", texto)\n",
    "    # Eliminar caracteres especiales innecesarios\n",
    "    texto = re.sub(r\"[^a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë0-9_\\s]\", \" \", texto) \n",
    "    # Pasar a min√∫sculas\n",
    "    texto = texto.lower() \n",
    "    # Quitar espacios m√∫ltiples\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "def tokenize_tweet(text):\n",
    "    return tokenizer.tokenize(limpiar_texto(text))\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize_tweet,\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(train_df.text)\n",
    "df_bow = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), df_bow.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69b82e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['neg','neu','pos','compound']] = pd.DataFrame(\n",
    "    test_df.text.map(lambda x: sia.polarity_scores(x)).tolist(),\n",
    "    index=test_df.index\n",
    ")\n",
    "\n",
    "test_df = test_df.join(\n",
    "    test_df['text'].apply(lambda x: pd.Series(sentiment_analyzer(x)[0]))\n",
    ").rename(columns={'label': 'sentimiento', 'score': 'score_global'})\n",
    "\n",
    "test_df['len'] = test_df.text.map(len)\n",
    "\n",
    "test_df[['tiene_url', 'palabras_claves', 'hashtags']] = test_df.text.apply(lambda x: pd.Series([\"SI\", count_claves(x), count_hashtags(x)] if \"url\" in tokens(x) else [\"NO\", count_claves(x), count_hashtags(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "904b5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_test = vectorizer.transform(test_df.text)\n",
    "df_bow_test = pd.DataFrame(X_bow_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), df_bow_test.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3434d619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zone</th>\n",
       "      <th>√≥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>10849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A gas thing just exploded and I heard screams ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3736</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>10850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWS: Flash Flood Warning Continued for Shelby ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>10851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @LivingSafely: #NWS issues Severe #Thunders...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7841</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>10852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#??? #?? #??? #??? MH370: Aircraft debris foun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4871</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>10853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Father-of-three Lost Control of Car After Over...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>10854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3 #Earthquake in 9Km Ssw Of Anza California ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>10855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evacuation order lifted for town of Roosevelt:...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>10859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#breaking #LA Refugio oil spill may have been ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>10860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a siren just went off and it wasn't the Forney...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4137</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6841</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side I'm at Walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.7650</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>10867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#stormchase Violent Record Breaking EF-5 El Re...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5849</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7593  10848     NaN      NaN   \n",
       "7594  10849     NaN      NaN   \n",
       "7595  10850     NaN      NaN   \n",
       "7596  10851     NaN      NaN   \n",
       "7597  10852     NaN      NaN   \n",
       "7598  10853     NaN      NaN   \n",
       "7599  10854     NaN      NaN   \n",
       "7600  10855     NaN      NaN   \n",
       "7601  10859     NaN      NaN   \n",
       "7602  10860     NaN      NaN   \n",
       "7603  10862     NaN      NaN   \n",
       "7604  10863     NaN      NaN   \n",
       "7605  10864     NaN      NaN   \n",
       "7606  10866     NaN      NaN   \n",
       "7607  10867     NaN      NaN   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target    neg    neu  \\\n",
       "7593  I just heard a really loud bang and everyone i...       0  0.000  0.687   \n",
       "7594  A gas thing just exploded and I heard screams ...       1  0.138  0.862   \n",
       "7595  NWS: Flash Flood Warning Continued for Shelby ...       1  0.156  0.844   \n",
       "7596  RT @LivingSafely: #NWS issues Severe #Thunders...       1  0.345  0.655   \n",
       "7597  #??? #?? #??? #??? MH370: Aircraft debris foun...       1  0.157  0.843   \n",
       "7598  Father-of-three Lost Control of Car After Over...       1  0.187  0.813   \n",
       "7599  1.3 #Earthquake in 9Km Ssw Of Anza California ...       1  0.000  1.000   \n",
       "7600  Evacuation order lifted for town of Roosevelt:...       1  0.000  1.000   \n",
       "7601  #breaking #LA Refugio oil spill may have been ...       1  0.000  1.000   \n",
       "7602  a siren just went off and it wasn't the Forney...       1  0.201  0.799   \n",
       "7603  Officials say a quarantine is in place at an A...       1  0.000  1.000   \n",
       "7604  #WorldNews Fallen powerlines on G:link tram: U...       1  0.249  0.751   \n",
       "7605  on the flip side I'm at Walmart and there is a...       1  0.122  0.878   \n",
       "7606  Suicide bomber kills 15 in Saudi security site...       1  0.328  0.574   \n",
       "7607  #stormchase Violent Record Breaking EF-5 El Re...       1  0.218  0.782   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  0.262  0.738   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  0.166  0.834   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  0.000  1.000   \n",
       "7611  Police investigating after an e-bike collided ...       1  0.345  0.655   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  0.000  1.000   \n",
       "\n",
       "        pos  compound sentimiento  ...  x  yeah year  years  yes  york  young  \\\n",
       "7593  0.313    0.6249    positive  ...  0     0    0      0    0     0      0   \n",
       "7594  0.000   -0.3736    negative  ...  0     0    0      0    0     0      0   \n",
       "7595  0.000   -0.3400     neutral  ...  0     0    0      0    0     0      0   \n",
       "7596  0.000   -0.7841     neutral  ...  0     0    0      0    0     0      0   \n",
       "7597  0.000   -0.4871    negative  ...  0     0    0      0    0     0      0   \n",
       "7598  0.000   -0.3182     neutral  ...  0     0    0      0    0     0      0   \n",
       "7599  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "7600  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "7601  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "7602  0.000   -0.4137    negative  ...  0     0    0      0    0     0      0   \n",
       "7603  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "7604  0.000   -0.6841    negative  ...  0     0    0      0    0     0      0   \n",
       "7605  0.000   -0.4939    negative  ...  0     0    0      0    0     0      0   \n",
       "7606  0.098   -0.7650     neutral  ...  0     0    0      0    0     0      0   \n",
       "7607  0.000   -0.5994     neutral  ...  0     0    0      0    0     0      0   \n",
       "7608  0.000   -0.4939     neutral  ...  0     0    0      0    0     0      0   \n",
       "7609  0.000   -0.5849    negative  ...  0     0    0      0    0     0      0   \n",
       "7610  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "7611  0.000   -0.7845    negative  ...  0     0    0      0    0     0      0   \n",
       "7612  0.000    0.0000     neutral  ...  0     0    0      0    0     0      0   \n",
       "\n",
       "      youth  zone  √≥  \n",
       "7593      0     0  0  \n",
       "7594      0     0  0  \n",
       "7595      0     0  0  \n",
       "7596      0     0  0  \n",
       "7597      0     0  0  \n",
       "7598      0     0  0  \n",
       "7599      0     0  0  \n",
       "7600      0     0  0  \n",
       "7601      0     0  0  \n",
       "7602      0     0  0  \n",
       "7603      0     0  0  \n",
       "7604      0     0  0  \n",
       "7605      0     0  0  \n",
       "7606      0     0  0  \n",
       "7607      0     0  0  \n",
       "7608      0     0  0  \n",
       "7609      0     0  0  \n",
       "7610      0     0  0  \n",
       "7611      0     0  0  \n",
       "7612      0     0  0  \n",
       "\n",
       "[20 rows x 1015 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52b59b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./data/train_with_features.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58308099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame principal como CSV (sin √≠ndice)\n",
    "test_df.to_csv(\"./data/test_with_features.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
