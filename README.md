# Proyecto: Natural Language Processing with Disaster Tweets

üöÄ **Demo online:**  [![Hugging Face Space](https://img.shields.io/badge/ü§ó%20Hugging%20Face-Space-yellow)](
https://huggingface.co/spaces/tomy07417/Natural-Language-Processing-with-Disaster-Tweets
)

Este repositorio re√∫ne el trabajo pr√°ctico (TP N.¬∫3) de la materia de Ciencia de Datos / Machine Learning, basado en la competencia de Kaggle "NLP - Getting Started" (https://www.kaggle.com/c/nlp-getting-started).

**Objetivo del proyecto**
- Construir modelos que predigan si un tweet describe un desastre real (`target` = 1) o no (`target` = 0).
- Desarrollar an√°lisis exploratorio, features, modelos baseline y modelos avanzados seg√∫n la consigna del TP.

Descripci√≥n de la competencia
- URL: `https://www.kaggle.com/c/nlp-getting-started`
- Resumen: el dataset contiene aproximadamente 10k tweets etiquetados a mano; el reto es predecir si un tweet habla sobre un desastre real.
- Nota: el dataset puede contener lenguaje profano u ofensivo.

Estructura del repositorio
- `*.ipynb`: notebooks con an√°lisis y modelos. Notebooks principales incluidos:
  - `exploracion_ml.ipynb` : visualizaciones y an√°lisis exploratorio (Parte I).
  - `regresion.ipynb`, `regresion_v2.ipynb` : regresi√≥n log√≠stica y baseline (Parte II).
  - `red_neuronal_v1.ipynb`, `red_neuronal_v2.ipynb`, `red_neuronal_v3.ipynb` : experimentos con redes neuronales (LSTM/GRU) y embeddings.
  - `random_forest.ipynb`, `xg_boost.ipynb` : modelos de la Parte III (dos modelos distintos adem√°s de la regresi√≥n log√≠stica).
  - `armado_features.ipynb` : notebook con transformaciones y creaci√≥n de features usadas por los modelos.
  - `words_desastres.txt` : lista de palabras relacionadas con desastres usada como referencia para features.

- `data/` : datos originales y con features.
  - `train.csv`, `test.csv` : archivos originales de la competencia.
  - `train_with_features.csv`, `test_with_features.csv` : versiones con features calculadas.
  - `sample_submission.csv` : formato de ejemplo para submissions.

- `plots/` : gr√°ficos generados durante el an√°lisis.
- `submission/` : CSVs generados para enviar a Kaggle (ej.: `logistic_regression_submission.csv`, `random_forest_submission.csv`, `xgb_sbert_submission.csv`, etc.).

Descripci√≥n de los archivos clave
- `train.csv` campos:
  - `id`: identificador del tweet
  - `text`: texto del tweet
  - `location`: (opcional) ubicaci√≥n
  - `keyword`: (opcional) palabra clave asociada al tweet
  - `target`: etiqueta (1 = desastre real, 0 = no)

C√≥mo reproducir los notebooks (recomendado)
1. Crear un entorno virtual e instalar dependencias m√≠nimas (ejemplo):

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt  # si existe
# o instalar paquetes comunes
pip install pandas numpy scikit-learn matplotlib seaborn nltk spacy tensorflow torch transformers
```

2. Abrir los notebooks en Jupyter / JupyterLab / Kaggle Notebooks.
3. Ejecutar las celdas en orden. Algunos notebooks esperan que `data/train_with_features.csv` y `data/test_with_features.csv` existan; si no existen, ejecutar `armado_features.ipynb` primero.

Formato de env√≠o (submit)
- El archivo de env√≠o debe tener dos columnas: `id` y `target` (0 o 1). Ejemplo:

```csv
id,target
12345,1
12346,0
```

M√©trica de evaluaci√≥n
- La competencia utiliza F1 (macro o micro seg√∫n la competencia ‚Äî revisar la p√°gina de Kaggle).
